<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<link rel="stylesheet" href="css/acl.css" type="text/css" />
  


 <title>Kalluri Shareef Babu </title>
  
  <meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1" />

 
</head>

<body>
<!--center everything-->
<div id="headwrapper">

	<!--Header-->
	<div id="header"> 
		
		<!-- LOGO -->
		<!--
		<div id="logo"><div id="LSE">AKS</div><div id="econ">Auditory NeuroScience</div></div> -->

		<!--Name-->
		<div id="name">Kalluri Shareef Babu</div>
		<div id="affiliation">Research Scholar<br />Department of Electronics and Communication Engineering <br /> National Institute of Technology Karnataka,Surathkal, India.</div> 
		<div id="navi">	<a href="index.html"><div id="off">Home</div></a>
						<a href="cv.html"><div id="off">CV</div></a>
						<a href="research.html"><div id="on">Research</div></a>
						<a href="courses.html"><div id="off">Courses</div></a>
						<a href="personal.html"><div id="off">Personal</div></a>
		</div>
	</div>
	<!--end Header-->
</div>
<div id="outerwrapper">
	<!--Content-->
	<div id="maincontent">
		<div id="onecol">
			<div id="subheader">Automatic Speaker Profiling from Short Duration Speech Data</div>
			<div id="subsubheader">Abstract:</div>
			<p align="justify">
			Many paralinguistic applications of speech demand the extraction of information about the speaker characteristics from as little speech data as possible. In this work, we explore the estimation of multiple physical parameters of the speaker from the short duration of speech in a multilingual setting. We explore  different feature streams for age and body build estimation derived from the speech spectrum at different resolutions, namely - short-term log-mel spectrogram,  formant features and harmonic  features of the speech.  The statistics of these features over the speech recording are used to learn a support vector regression model for speaker age and body build estimation. The experiments  performed on the TIMIT dataset  show that each of the individual features is able to achieve results that outperform previously published results in height and age estimation. Furthermore, the estimation errors from these  different feature streams are complementary, which allows the  combination of estimates from these feature streams to further improve the results. The combined system from short audio snippets  achieves a performance of 5.2 cm, and 4.8 cm  in Mean Absolute Error (MAE) for male and female  respectively for height estimation. Similarly in age estimation the MAE is of 5.2 years, and 5.6 years for male, and female  speakers respectively. We also extend the same physical parameter estimation to other body build parameters like shoulder width, waist size and weight along with height on a dataset we collected for speaker profiling. The duration analysis of the proposed scheme shows that the state of the art results can be achieved using only around 1-2 seconds of speech data. To the best of our knowledge, this is the first attempt to use a common set of features  for estimating the different physical traits of a speaker.
			<p align="justify">
			 
			<div id="subsubheader">Download:</div>
			<div id="paperlink"><a href="https://drive.google.com/file/d/1PZWXP35YnsWlvfoV8VhkuuZCGa9tLfui/view?usp=sharing" id="paperlink">PAPER</a></div>
			
			
			
			<div id="subheader">A Deep Neural Network based End to End Model for Joint Height and Age Estimation from Short Duration Speech</div>
			<div id="subsubheader">Abstract:</div>
			<p align="justify">
			Automatic height and age prediction of a speaker has a wide variety of applications in speaker profiling, forensics etc. Often in such applications only a few seconds of speech data is available  to reliably estimate the speaker parameters. Traditionally, age and height were predicted separately using different estimation algorithms. In this work, we propose a unified DNN architecture to predict both height and age of a speaker for short durations of speech. A novel initialization scheme for the deep neural architecture is introduced, that avoids the requirement for a large training dataset. We evaluate the system on TIMIT dataset where the mean duration of speech segments is around 2.5s. The DNN  system is able to improve the age RMSE by at least 0.6 years as compared to a conventional support vector regression system trained on Gaussian Mixture Model  mean supervectors. The system achieves an RMSE error of 6.85 and 6.29cm for male and female height prediction. In case of age estimation, the RMSE errors are 7.60 and 8.63 years for male and female respectively. Analysis of shorter speech  segments reveals that even with 1 second speech input the performance degradation is at most 3% compared to the full duration speech files.
			<p align="justify">
			 
			<div id="subsubheader">Download:</div>
			<div id="paperlink"><a href="https://drive.google.com/open?id=161bidEJHqAKJPZnAKeHO828JsUtCzXdk" id="paperlink">PAPER</a></div>
			
			<div id="subheader">Robust Features for Automatic Estimation of Physical Parameters from Speech</div>
			<div id="subsubheader">Abstract:</div>
			<p align="justify">
			Estimating speaker's physical parameters like height, weight and shoulder size can assist in voice forensics by providing additional knowledge about the speaker. In this work, statistics of the components of background GMM are employed as features in estimating the physical parameters. These features improved the performance of height and shoulder size estimation as compared to our earlier attempt based on a Bag of Word representation. The robustness of the features is validated using two different training subsets containing different languages.
			<p align="justify">
			<div id="subsubheader">Download:</div>
			<div id="paperlink"><a href="https://ieeexplore.ieee.org/document/8228097" id="paperlink">PAPER</a> <a href="https://drive.google.com/open?id=1U-k3lXR9SF8cXkNwH4RhH_Qrj1ZpXqEP" id="poster"> Poster </a> </div>
			<div id="subheader">Estimating Multiple Physical Parameters from Speech Data</div>
			<div id="subsubheader">Abstract:</div>
			<p align="justify">
			In this work, we explore prediction of different physical parameters from speech data. We aim to predict shoulder size and waist size of people from speech data in addition to the conventional height and weight parameters. A data-set with this information is created from 207 volunteers. A bag of words representation based on log magnitude spectrum is used as features. A support vector regression predicts the physical parameters from the bag of the words representation. The system is able to achieve a root mean square error of 6.6 cm for height estimation, 2.6cm for shoulder size, 7.1cm for waist size and 8.9 kg for weight estimation. The results of height estimation is on par with state of the art results. 
			<p align="justify">
			<div id="subsubheader">Download:</div>
			<div id="paperlink"><a href="https://ieeexplore.ieee.org/abstract/document/7738873" id="paperlink">PAPER</a> <a href="https://drive.google.com/open?id=1l-BqivUl6-F7K5Qr0g7_Wqi1jNvQjAuA" id="poster"> Poster </a> </div>
			<div id="subheader">Study of Wireless Channel Effects on Audio Forensics</div>
			<div id="subsubheader">Abstract:</div>
			<p align="justify">
			In this work, we try to study the effect of a wireless channel on physical parameter prediction based on speech data. Speech data from 207 speakers along with corresponding speaker's height and weight is collected. A three path Rayleigh fading channel with typical values of Doppler shift, path gain and path delay is utilized to create the mobile channel output audio. A Bag of Words (BoW) representation based on log magnitude spectrum is used as features. Support Vector Regression (SVR) predicts the physical parameter of the speaker from the BoW representation. The proposed system is able to achieve a Root Mean Square Error (RMSE) of 6.6 cm for height estimation and 8.9 Kg for weight estimation for clean speech. The effect of Rayleigh channel increase the RMSE values to 8.17 cm and 11.84 Kg respectively for height and weight.			
			<p align="justify">
			<div id="subsubheader">Download:</div>
			<div id="paperlink"><a href="https://ieeexplore.ieee.org/document/8385600" id="paperlink">PAPER</a>  </div>
			<div id="subheader">NISP: A Multi-lingual Multi-accent Dataset for Speaker Profiling</div>
			<div id="subsubheader">Abstract:</div>			
			<p align="justify">
			Many commercial and forensic applications of speech demand the extraction of information about the speaker characteristics, which falls into the broad category of speaker profiling. The speaker characteristics needed for profiling include physical traits of the speaker like height, age, and gender of the speaker along with the native language of the speaker. Many of the datasets available have only partial information for speaker profiling. In this paper, we attempt to overcome this limitation by developing a new dataset which has speech data from five different Indian languages along with English.  The metadata information for speaker profiling applications like linguistic information, regional information, and physical characteristics of a speaker are also collected.  We call this dataset as NITK-IISc Multilingual Multi-accent Speaker Profiling (NISP) dataset. The description of the dataset, potential applications, and baseline results for speaker profiling on this dataset are provided in this paper. 			
			<p align="justify">
			<div id="subsubheader">Download:</div>
			<div id="paperlink"><a href="https://arxiv.org/abs/2007.06021" id="paperlink">PAPER</a>  </div>
			
			<div id="subheader">COVID-19 Patient Detection from Telephone Quality Speech Data</div>
			<div id="subsubheader">Abstract:</div>			
			<p align="justify">
			In this paper, we try to investigate the presence of cues about the COVID-19 disease in the speech data. We use an approach that is similar to speaker recognition. Each sentence is represented as super vectors of short term Mel filter bank features for each phoneme. These features are used to learn a two-class classifier to separate the COVID-19 speech from normal. Experiments on a small dataset collected from YouTube videos show that an SVM classifier on this dataset is able to achieve an accuracy of 88.6% and an F1-Score of 92.7%. Further investigation reveals that some phone classes, such as nasals, stops, and mid vowels can distinguish the two classes better than the others. 
			<p align="justify">
			<div id="subsubheader">Download:</div>
			<div id="paperlink"><a href="https://arxiv.org/abs/2011.04299" id="paperlink">PAPER</a>  </div>
			
			<div id="subheader">COVID-19 Detection from Spectral features on the DiCOVA Dataset</div>
			<div id="subsubheader">Abstract:</div>			
			<p align="justify">
			In this paper we investigate the cues of COVID-19 on sustained phonation of Vowel-/i/, deep breathing and number counting data of the DiCOVA dataset. We use an ensemble of classifiers trained on different features, namely, super-vectors, formants, harmonics and MFCC features. We fit a two-class Weighted SVM classifier to separate the COVID-19 audio from Non-COVID-19 audio. Weighted penalties help mitigate the challenge of class imbalance in the dataset. The results are reported on the stationary (breathing, Vowel-/i/) and non-stationary(counting data) data using individual and combination of features on each type of utterance. We find that the Formant information plays a crucial role in classification. The proposed system resulted in an AUC score of 0.734 for cross validation,and 0.717 for evaluation dataset.
			<p align="justify">
			<div id="subsubheader">Download:</div>
			<div id="paperlink"><a href="https://www.isca-speech.org/archive/pdfs/interspeech_2021/ritwik21_interspeech.pdf" id="paperlink">PAPER</a>  </div>
			
		

			
			<div id="subheader">Publications</div>
			<div id="pubAuthor">Kalluri, Shareef Babu , Deepu Vijayasenan, Sriram Ganapathy </div>
			<div id="pubTitle"> "Automatic Speaker Profiling from Short Duration Speech Data" </div> 
			<em> Speech Communications, </em> vol.121, p 16-28, May 2020
		
                        <div id="pubAuthor"> Shareef Babu Kalluri, Deepu Vijayasenan, Sriram Ganapathy, Ragesh Rajan M, Prashant Krishnan </div>
			<div id="pubTitle"> "NISP: A Multi-lingual Multi-accent Dataset for Speaker Profiling" </div>  in the proceedings of the 
			<em>  46th IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). </em> Toronto, Ontario, Canada, IEEE, 2021. 			
			<div id="pubAuthor">Kalluri, Shareef Babu , Deepu Vijayasenan, Sriram Ganapathy </div>
			<div id="pubTitle"> "A Deep Neural Network based End to End Model for Joint Height and Age Estimation from Short Duration Speech" </div> in the proceedings of the 
			<em> 44th IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP).</em> Brighton, United Kingdom, 2019, pp. 6580-6584, IEEE, 2019. 
			<div id="pubAuthor">Babu, Kalluri Shareef, and Deepu Vijayasenan.   </div>
			<div id="pubTitle">"Robust Features for Automatic Estimation of Physical Parameters from Speech",</div> in the proceedings of the
			<em>TENCON 2017-2017 IEEE Region 10 Conference </em>, IEEE, 2017.
			<div id="pubAuthor"> Kalluri, Shareef Babu, Ashwin Vijayakumar, Deepu Vijayasenan, and Rita Singh.</div>  
			<div id="pubTitle"> "Estimating multiple physical parameters from speech data." </div> in the proceedings of the
			<em> IEEE 26th International Workshop on Machine Learning for Signal Processing (MLSP).</em> IEEE, 2016.
			<div id="pubAuthor"> Vijayasenan, Deepu, Shareef Babu Kalluri, K. Sreekanth, and Ansal Issac. </div>
			<div id="pubTitle"> "Study of Wireless Channel Effects on Audio Forensics" </div>in the proceedings of the
			<em> 22nd Annual International Conference on Advanced Computing and Communication (ADCOM), pp. 33-37.</em> IEEE, 2016.
			
			
			<div id="pubAuthor">Ritwik, Kotra Venkata Sai, Shareef Babu Kalluri, and Deepu Vijayasenan.  </div>
			<div id="pubTitle">  "COVID-19 Detection from Spectral Features on the DiCOVA Dataset." </div>in the proceedings of the
			<em> Interspeech. 2021., pp. 936-940.</em>
			
			<div id="pubAuthor"> Kotra Venkata Sai Ritwik, Shareef Babu Kalluri, Deepu Vijayasenan </div>
			<div id="pubTitle"> "COVID-19 Patient Detection from Telephone Quality Speech Data" </div>in 
			<em> arXiv preprint arXiv:2011.04299 (2020).				
			
			
		</div>
	</div>
	<!--end Content-->
</div>

		<!--Foot-->
	<div id="fooder">Office: Intelligent User Interface Lab (IUI-Lab) / shareefbabu1 AT gmail DOT com   <br />
	Postal: Intelligent User Interface Lab (IUI-Lab) / Dept.of Computer and Information Science / Seikei University / Tokyo / Japan</div>
	<!--end Foot-->

<!--end center everything-->
</body>
</html>
